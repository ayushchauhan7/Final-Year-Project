{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7046ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "try:\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "except ImportError:\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077077f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training directory: c:\\Users\\Abhay Tyagi\\OneDrive - ABES\\Desktop\\4th Year Project\\Datasets\\Brain Tumor Dataset\\Training\n",
      "Testing directory: c:\\Users\\Abhay Tyagi\\OneDrive - ABES\\Desktop\\4th Year Project\\Datasets\\Brain Tumor Dataset\\Testing\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = r'c:\\Users\\Abhay Tyagi\\OneDrive - ABES\\Desktop\\4th Year Project\\Datasets\\Brain Tumor Dataset\\Training'\n",
    "TEST_DIR = r'c:\\Users\\Abhay Tyagi\\OneDrive - ABES\\Desktop\\4th Year Project\\Datasets\\Brain Tumor Dataset\\Testing'\n",
    "print(\"Training directory:\", TRAIN_DIR)\n",
    "print(\"Testing directory:\", TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb4a90",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce812c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dir exists: True\n",
      "Testing dir exists: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dir exists:\", os.path.exists(TRAIN_DIR))\n",
    "print(\"Testing dir exists:\", os.path.exists(TEST_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6854f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 974 images belonging to 2 classes.\n",
      "Found 243 images belonging to 2 classes.\n",
      "Found 220 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c99baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: {'meningioma_tumor': 0, 'no_tumor': 1}\n",
      "Number of training samples: 974\n",
      "Number of validation samples: 243\n",
      "Number of test samples: 220\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes found:\", train_generator.class_indices)\n",
    "print(\"Number of training samples:\", train_generator.samples)\n",
    "print(\"Number of validation samples:\", validation_generator.samples)\n",
    "print(\"Number of test samples:\", test_generator.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8eb6fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created and compiled successfully!\n",
      "\n",
      "Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,850,242</span> (90.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,850,242\u001b[0m (90.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,530</span> (1.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m262,530\u001b[0m (1.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Parameters: 23,850,242\n",
      "Trainable Parameters: 262,530\n",
      "Non-trainable Parameters: 23,587,712\n"
     ]
    }
   ],
   "source": [
    "def create_brain_tumor_model():\n",
    "    # Create input layer\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    \n",
    "    # Create ResNet50 base model\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model using Functional API (more stable for saving/loading)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name='dense_1')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    outputs = tf.keras.layers.Dense(2, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "model = create_brain_tumor_model()\n",
    "\n",
    "# Build the model with a dummy input to initialize weights\n",
    "dummy_input = tf.random.normal((1, 224, 224, 3))\n",
    "_ = model(dummy_input)\n",
    "\n",
    "print(\"Model created and compiled successfully!\")\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Check trainable parameters\n",
    "total_params = model.count_params()\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable Parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d2e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meningioma_tumor: 822 images\n",
      "no_tumor: 395 images\n",
      "\n",
      "Class balance check:\n",
      "Ideal: Each class should have similar number of images\n",
      "Problem: If one class has <50% of others, it's imbalanced\n"
     ]
    }
   ],
   "source": [
    "# Add this cell to check class distribution\n",
    "import os\n",
    "\n",
    "def check_dataset_quality():\n",
    "    train_dir = r'c:\\Users\\Abhay Tyagi\\OneDrive - ABES\\Desktop\\4th Year Project\\Datasets\\Brain Tumor Dataset\\Training'\n",
    "    \n",
    "    for class_name in os.listdir(train_dir):\n",
    "        class_path = os.path.join(train_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"{class_name}: {count} images\")\n",
    "    \n",
    "    print(\"\\nClass balance check:\")\n",
    "    print(\"Ideal: Each class should have similar number of images\")\n",
    "    print(\"Problem: If one class has <50% of others, it's imbalanced\")\n",
    "\n",
    "check_dataset_quality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d58f097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Trainable parameters before training: 262,530\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abhay Tyagi\\OneDrive - ABES\\Desktop\\4th Year Project\\Project\\Medical_Image_Analysis_System\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.6133 - loss: 0.8612 - val_accuracy: 0.6830 - val_loss: 0.6236 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 995ms/step - accuracy: 0.8125 - loss: 0.4895"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhay Tyagi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8125 - loss: 0.2529 - val_accuracy: 0.8421 - val_loss: 0.1931 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.6598 - loss: 0.6589 - val_accuracy: 0.7500 - val_loss: 0.5227 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6562 - loss: 0.4452 - val_accuracy: 0.7368 - val_loss: 0.2616 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.7172 - loss: 0.6010 - val_accuracy: 0.7366 - val_loss: 0.5223 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6250 - loss: 0.3361 - val_accuracy: 0.6316 - val_loss: 0.3185 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7309 - loss: 0.5589\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.7300 - loss: 0.5599 - val_accuracy: 0.7455 - val_loss: 0.5307 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7857 - loss: 0.2380 - val_accuracy: 0.8947 - val_loss: 0.1857 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.7176 - loss: 0.5694 - val_accuracy: 0.7321 - val_loss: 0.5222 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.6250 - loss: 0.3379 - val_accuracy: 0.7895 - val_loss: 0.2626 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.7506 - loss: 0.5412 - val_accuracy: 0.7679 - val_loss: 0.4957 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6562 - loss: 0.3662 - val_accuracy: 0.6316 - val_loss: 0.3064 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7296 - loss: 0.5614\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.7302 - loss: 0.5610 - val_accuracy: 0.7589 - val_loss: 0.5155 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.2683 - val_accuracy: 0.7895 - val_loss: 0.2054 - learning_rate: 2.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.7365 - loss: 0.5437 - val_accuracy: 0.7545 - val_loss: 0.5111 - learning_rate: 2.5000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.3025 - val_accuracy: 0.8947 - val_loss: 0.1994 - learning_rate: 2.5000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.7635 - loss: 0.5287 - val_accuracy: 0.7545 - val_loss: 0.5055 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.6562 - loss: 0.6312\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6562 - loss: 0.3261 - val_accuracy: 0.8421 - val_loss: 0.2235 - learning_rate: 2.5000e-04\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving model: Unable to synchronously create dataset (name already exists)\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.6545 - loss: 0.6769\n",
      "Test Accuracy: 0.5682\n",
      "Training plots saved successfully!\n",
      "Training completed!\n",
      "\n",
      "=== Training Summary ===\n",
      "Final Training Accuracy: 0.6562\n",
      "Final Validation Accuracy: 0.8421\n",
      "Test Accuracy: 0.5682\n",
      "Models saved in: ../trained_models/\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Define callbacks for better training\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Trainable parameters before training: {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,}\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create directory and save model with unique name\n",
    "try:\n",
    "    # Ensure directory exists\n",
    "    os.makedirs('../trained_models', exist_ok=True)\n",
    "    \n",
    "    # Create unique filename to avoid conflicts\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_filename = f'../trained_models/brain_tumor_model_{timestamp}.h5'\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(model_filename)\n",
    "    print(f\"Model saved successfully as: {model_filename}\")\n",
    "    \n",
    "    # Also save with standard name (overwrite if exists)\n",
    "    try:\n",
    "        model.save('../trained_models/brain_tumor_model.h5')\n",
    "        print(\"Model also saved as: brain_tumor_model.h5\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save with standard name: {e}\")\n",
    "        print(\"But timestamped version was saved successfully!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Safe plotting with fallback\n",
    "try:\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')  # Non-interactive backend\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Ensure directory exists for plots\n",
    "    os.makedirs('../trained_models', exist_ok=True)\n",
    "    plt.savefig('../trained_models/training_plots.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()  # Close figure to free memory\n",
    "    print(\"Training plots saved successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not create plots: {e}\")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Print training summary\n",
    "print(\"\\n=== Training Summary ===\")\n",
    "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Models saved in: ../trained_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce9f5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved in native Keras format successfully!\n"
     ]
    }
   ],
   "source": [
    "# Convert existing model to native Keras format (Keras 3 recommended)\n",
    "try:\n",
    "    # Save in native Keras format (.keras extension)\n",
    "    model.save('../trained_models/brain_tumor_model.keras')\n",
    "    print(\"✅ Model saved in native Keras format successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Keras format conversion failed: {e}\")\n",
    "    \n",
    "    # Fallback: Try TensorFlow's SavedModel format\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        tf.saved_model.save(model, '../trained_models/brain_tumor_savedmodel')\n",
    "        print(\"✅ Model saved as TensorFlow SavedModel successfully!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ TensorFlow SavedModel also failed: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d366cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
